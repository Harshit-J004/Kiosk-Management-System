# ğŸ§  Multi-Store Kiosk Management System

An **agentic AI-powered platform** for managing kiosks across multiple stores. This system integrates **CrewAI**, **LangChain**, and modular tools to automate kiosk diagnostics, order operations, alert monitoring, and performance analytics â€” all driven by LLMs.

---

## ğŸš€ Features

- âœ… Full multi-store agentic AI architecture
- ğŸ“¦ Intelligent order processing and revenue analysis
- ğŸ–¥ï¸ Kiosk health checks, restarts, and maintenance
- ğŸš¨ Real-time alert monitoring and resolution
- â±ï¸ Latency reporting and performance metrics
- ğŸ¤– OpenAI + Ollama-compatible LLM setup
- ğŸ“Š CLI interface for managing all stores

---

## ğŸ§  Architecture Flow

```

User Input (main menu)
â”‚
â””â”€â”€> EnhancedSupervisor (L0)
â””â”€â”€ OperatorApp for each store (L1)
â”œâ”€â”€ Kiosk Specialist (L2)
â”œâ”€â”€ Order Specialist (L2)
â””â”€â”€ Alert Specialist (L2)
â””â”€â”€ Tools: \_run() via EnhancedTool (L3)

```

Each store's agents are executed via sequential `Crew` with `Task` + `expected_output`.

---

## ğŸ§© Core Components

### ğŸ¯ Supervisor (`EnhancedSupervisor`)
- Manages all stores and initializes operator apps
- Supports full AI ops, quick status, restarts, and monitoring

### ğŸ› ï¸ Operator App (`EnhancedOperatorApp`)
- Instantiated per store
- Composed of specialized agents
- Three main crews:
  - Diagnostics Crew
  - Operations Crew
  - Maintenance Crew

### ğŸ¤– Agents
- **Multi-Store Kiosk Specialist**
- **Multi-Store Order Specialist**
- **Multi-Store Alert Specialist**

Each uses a tool to execute based on task prompts.

### ğŸ§° Tools
- `EnhancedKioskTool`: Diagnostics, restart, health
- `EnhancedOrderTool`: Process orders, revenue, priority
- `EnhancedAlertTool`: Monitor, resolve, and log alerts

---

## ğŸ“‚ Example CLI Options

```

1. View Supervisor Dashboard
2. Run Monitoring Cycle
3. Run Full AI Operations (CrewAI)
4. Restart Store Systems
5. Quick Status
6. Emergency Response
7. Start Continuous Monitoring
8. Stop Continuous Monitoring
9. View Latency Report
10. Exit

````

---

## âš™ï¸ Setup Instructions

### 1. Install Dependencies

```bash
pip install -r requirements.txt
````

Or manually:

```bash
pip install crewai langchain langchain-openai python-dotenv
```

### 2. LLM Configuration

#### ğŸ”‘ OpenAI (Recommended)

Create a `.env` file:

```
OPENAI_API_KEY=sk-xxxxxx
```

Use in Python:

```python
from dotenv import load_dotenv
load_dotenv()
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)
```

#### ğŸ’¡ Ollama (Alternative - Local)

Install Ollama and pull:

```bash
ollama pull llama3
ollama serve
```

In code:

```python
from langchain_community.llms import Ollama
llm = Ollama(model="llama3", base_url="http://localhost:11434")
```

---

## ğŸ“ˆ Performance Tracking

The system logs every operation's:

* Start/End time
* Duration
* Success/failure
* Store ID

Command `View Latency Report` displays these logs in real time.

---

## ğŸ“Š Dashboard Overview

Shows:

* Total stores, kiosks, orders
* Online kiosk counts
* Active alerts
* Monitoring status
* Recent latency metrics

---

## ğŸ”® Future Enhancements

* âœ… Vector DB integration (for memory/log search)
* ğŸ” Slack/email alerting
* ğŸ“¡ Web dashboard (Streamlit or Flask)
* ğŸ“Š Real-time charting of performance

---

## ğŸ Author

Built by [Harshit Joshi](https://github.com/yourusername)
A modular, production-ready project demonstrating **agentic AI operations for real-world IoT kiosks**.

---
